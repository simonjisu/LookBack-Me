Look Back - Me
===

# 2018.12.31

Write what i've done, write plans In `TODO` !!!

---

## Study

### Study Group

#### Joined - recolabs part02

* from 2018.01 ~ 2018.03
* About: Deep learning using KERAS
* Presentation: RNN & LSTM Part
* Learned: Using numpy to code RNN & its' backpropagation (BPTT)  
* Wrote: 2 Blog Article

#### Create - DeepNLP

* from 2018.07.25 ~
* About: Natural Language Processing Paper Study + Code Implementation
* [Presentation](https://docs.google.com/presentation/d/18AUKWMRClrobLmtFBQWqwlyw-Llouh3Feii5DyNfvnQ/edit?usp=sharing): A Neural Probabilistic Language Model - Yoshua Bengio
* [Implementations](https://github.com/simonjisu/deepnlp_study): 
	* Neural Network Language Modeling
	* Word2Vec with NEG & Visualization
	* (working on) Transformer
	* (working on) BiDAF

### Personal Study

#### Paper Read 

* A Structured Self-Attentive Sentence Embedding - Zhouhan Lin
* Learning Phrase Representation using RNN Encoder-Decoder for Statistical Machine Translation - Kyunghyun Cho
* Neural Machine Translation by Jointly Learning to Align and Translate - Dzmitry Bahdanau
* A Neural Probabilistic Language Model - Yoshua Bengio
* Distributed Representations of Words and Phrases and their Compositionality - Mikolov
* word2vec Explained: deriving Mikolov et al.â€™s negative-sampling word-embedding method - Yoav Goldberg
* GloVe: Global Vectors for Word Representation - Jeffrey Pennington
* Attention is all you need - Ashish Vaswani
* Bi-Directional Attention Flow for Machine Comprehension - Minjoon Seo

#### Paper Implementations 

* [End-to-end Memory Network](https://github.com/simonjisu/E2EMN)
* [Neural Machine Translation by Jointly Learning to Align and Translate](https://github.com/simonjisu/NMT)

#### GPU computer settings

* Bought a Computer for Deep Learning & Changed GPU from GTX 1060 to GTX 1080 ti :)
* Install Ubuntu Server In my computer & Remote Turn On/Off (WOL)
* Installed (hell) CUDA library & jupyter notebook works well on remote
* Learned Port Forwarding
* Getting familiar with Linux Terminal & vi command

#### Lectures Taken

* Deep Learning with PyTorch @ Fast Campus
* NLP with Deep Learning - Kyunghyun Cho @ Naver Connect 
* Deep Learning AI - Andrew Ng @ YouTube

### Participatations

* [Naver AI Colloquium 2018](https://simonjisu.github.io/naverai2018/2018/03/30/naveraicolloquium2018.html)
* [Little Big Data](https://simonjisu.github.io/datascience/2018/04/21/biglittledata.html)
* Pycon 2018
* [How to be a good Deep Learning Researcher?](https://github.com/simonjisu/how2start_ai/blob/master/%EC%A2%8B%EC%9D%80%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%97%B0%EA%B5%AC%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%90%98%EA%B8%B0.md)

<br>

## Working

### Start working @ Naver Connect

* from 2018.02.26 ~ 
* Published (Make an online lecture on [edwith](https://www.edwith.org/)) "NLP with Deep Learning"
* Published "Deep Learning ai"
* Managing "Deep Learning for Everyone season 2"

---

<br>

# Study Plans In 2019

### PRML study

* [https://simonjisu.github.io/prml_study/](https://simonjisu.github.io/prml_study/)
* Study basic machine learning theory, lay the ground work : "Pattern Recognition and Machine Learning" - Christopher Bishop

### Keep on NLP Paper reading & implementation

* BERT
* bigbird
* transformer

### Try to Learn New Things

* Flask
* Spark (PySpark)
* Reinforcement Learning
